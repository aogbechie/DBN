{
    "collab_server" : "",
    "contents" : "\n# is x a vector (as opposed to a matrix)?\nis.vector = function(x) {\n\n  is.null(dim(x)) ||\n  (length(dim(x)) == 2) &&\n  (dim(x)[2] == 1)\n\n}#IS.VECTOR\n\n# is x a real number?\nis.real.number = function(x) {\n\n  is.numeric(x) &&\n  (length(x) == 1) &&\n  is.finite(x)\n\n}#IS.REAL\n\n# is x a vector of real number?\nis.real.vector = function(x) {\n\n  is.numeric(x) &&\n  all(is.finite(x))\n\n}#IS.REAL.VECTOR\n\n# is x a positive number?\nis.positive = function(x) {\n\n  is.numeric(x) &&\n  (length(x) == 1) &&\n  is.finite(x) &&\n  (x > 0)\n\n}#IS.POSITIVE\n\n# is x a non-negative number?\nis.non.negative = function(x) {\n\n  is.numeric(x) &&\n  (length(x) == 1) &&\n  is.finite(x) &&\n  (x >= 0)\n\n}#IS.NON.NEGATIVE\n\n# is x a positive integer?\nis.positive.integer = function(x) {\n\n  is.positive(x) && ((x %/% 1) == x)\n\n}#IS.POSITIVE.INTEGER\n\n# is x a vector of positive numbers?\nis.positive.vector = function(x) {\n\n  is.numeric(x) &&\n  all(is.finite(x)) &&\n  all(x > 0)\n\n}#IS.POSITIVE.VECTOR\n\n# is x a vector of non-negative numbers?\nis.nonnegative.vector = function(x) {\n\n  is.numeric(x) &&\n  all(is.finite(x)) &&\n  all(x >= 0)\n\n}#IS.NONNEGATIVE.VECTOR\n\n# is x a probability?\nis.probability = function(x) {\n\n  is.numeric(x) &&\n  (length(x) == 1) &&\n  is.finite(x) &&\n  (x >= 0) &&\n  (x <= 1)\n\n}#IS.PROBABILITY\n\n# is x a vector of probabilities?\nis.probability.vector = function(x) {\n\n  is.numeric(x) &&\n  all(is.finite(x)) &&\n  all(x >= 0) &&\n  all(x <= 1) &&\n  any(x > 0)\n\n}#IS.PROBABILITY.VECTOR\n\n# is x a single character string?\nis.string = function(x) {\n\n  is.character(x) &&\n  (length(x) == 1) &&\n  !any(is.na(x)) &&\n  any(x != \"\")\n\n}#IS.STRING\n\n# is x a vector of character strings?\nis.string.vector = function(x) {\n\n  is.character(x) &&\n  !any(is.na(x)) &&\n  any(x != \"\")\n\n}#IS.STRING\n\nis.ndmatrix = function(x) {\n\n  is(x, c(\"table\", \"matrix\", \"array\"))\n\n}#IS.NDMATRIX\n\n# is x a symmetric matrix?\nis.symmetric = function(x) {\n\n  .Call(\"is_symmetric\",\n        matrix = x)\n\n}#IS.SYMMETRIC\n\n# does x satisfy the Cauchy-Schwarz inequality?\nis.cauchy.schwarz = function(x) {\n\n  .Call(\"is_cauchy_schwarz\",\n        matrix = x)\n\n}#IS.CAUCHY.SCHWARZ\n\n# are all numeric values in the data frame fimite?\ncheck.data.frame.finite = function(x) {\n\n  .Call(\"data_frame_finite\",\n        data = x)\n\n}#DATA.FRAME.FINITE\n\n# check the data set.\ncheck.data = function(x, allowed.types = available.data.types,\n    allow.levels = FALSE) {\n\n  # check the data are there.\n  if (missing(x))\n    stop(\"the data are missing.\")\n  # x must be a data frame.\n  if(!is.data.frame(x))\n    stop(\"the data must be in a data frame.\")\n  # check the data for NULL/NaN/NA.\n  if (missing.data(x))\n    stop(\"the data set contains NULL/NaN/NA values.\")\n  # check which type of data we are dealing with.\n  type = data.type(x)\n\n  # check whether the variables are either all continuous or all discrete.\n  if (type %!in% allowed.types)\n    stop(\"valid data types are:\\n\",\n      sprintf(\"    * %s.\\n\", data.type.labels[allowed.types]))\n\n  # checks specific to a particular data type.\n  if (type %in% discrete.data.types) {\n\n    for (col in names(x)) {\n\n      # check the number of levels of discrete variables, to guarantee that\n      # the degrees of freedom of the tests are positive.\n      if (nlevels(x[, col]) < 2)\n        stop(\"variable \", col, \" must have at least two levels.\")\n\n      # warn about levels with zero frequencies, it's not necessarily wrong\n      # (data frame subsetting) but sure is fishy.\n      if (!allow.levels && any(table(x[, col]) == 0))\n        warning(\"variable \", col, \" has levels that are not observed in the data.\")\n\n    }#FOR\n\n  }#THEN\n  else if (type == \"continuous\") {\n\n    # all values must be finite to have finite mean and variance.\n    check.data.frame.finite(x)\n\n  }#THEN\n\n  return(type)\n\n}#CHECK.DATA\n\n# check nodes (not necessarily from a bn object).\ncheck.nodes = function(nodes, graph = NULL, min.nodes = 1, max.nodes = Inf) {\n\n  # a node is needed.\n  if (missing(nodes))\n    stop(\"no node specified.\")\n  # nodes must be a vector of character strings.\n  if (!is(nodes, \"character\"))\n    stop(\"nodes must be a vector of character strings, the labels of the nodes.\")\n  # no duplicates allowed.\n  if (any(duplicated(nodes)))\n     stop(\"node labels must be unique.\")\n  # no empty strings.\n  if (any(is.na(nodes)) || any(nodes == \"\"))\n    stop(\"an empty string is not a valid node label.\")\n  # maximum number of nodes requirement.\n  if (length(nodes) > max.nodes)\n    stop(\"at most \", max.nodes, \" node(s) needed.\")\n  # minimum number of nodes requirement (usually 1).\n  if (length(nodes) < min.nodes)\n    stop(\"at least \", min.nodes, \" node(s) needed.\")\n  # node must be a valid node label.\n  if (!is.null(graph)) {\n\n    if (is(graph, \"bn\")) {\n\n      if (any(nodes %!in% names(graph$nodes)))\n        stop(\"node(s)\", paste0(\" '\", nodes[nodes %!in% names(graph$nodes)], \"'\"),\n             \" not present in the graph.\")\n\n    }#THEN\n    else if (is(graph, \"bn.fit\")) {\n\n      if (any(nodes %!in% names(graph)))\n        stop(\"node(s)\", paste0(\" '\", nodes[nodes %!in% names(graph)], \"'\"),\n             \" not present in the graph.\")\n\n    }#THEN\n    else if (is.character(graph)) {\n\n      if (any(nodes %!in% graph))\n        stop(\"node(s)\", paste0(\" '\", nodes[nodes %!in% graph], \"'\"),\n             \" not present in the graph.\")\n\n    }#THEN\n\n  }#THEN\n\n}#CHECK.NODES\n\n# check an arc set.\ncheck.arcs = function(arcs, nodes) {\n\n  # sanitize the set of arcs.\n  if (is(arcs, \"matrix\") || is(arcs, \"data.frame\")) {\n\n     if (dim(arcs)[2] != 2)\n       stop(\"arc sets must have two columns.\")\n     if (!all(sapply(arcs, class) == \"character\"))\n       stop(\"node labels in arc sets must be character strings.\")\n\n     if (is.data.frame(arcs))\n       arcs = as.matrix(cbind(as.character(arcs[, 1]),\n         as.character(arcs[, 2])))\n\n     # be sure to set the column names.\n     dimnames(arcs) = list(c(), c(\"from\", \"to\"))\n\n  }#THEN\n  else if (is.character(arcs)) {\n\n    # if there is an even number of labels fit them into a 2-column matrix.\n    if ((length(arcs) %% 2) != 0)\n      stop(\"arc sets must have two columns.\")\n\n    arcs = matrix(arcs, ncol = 2, byrow = TRUE,\n              dimnames = list(c(), c(\"from\", \"to\")))\n\n  }#THEN\n  else {\n\n     stop(\"an arc set must be a matrix or data.frame with two columns.\")\n\n  }#ELSE\n\n  # nodes must be valid node labels.\n  if (any(arcs %!in% nodes))\n    stop(\"node(s)\", paste0(\" '\", unique(arcs[arcs %!in% nodes]), \"'\"),\n         \" not present in the graph.\")\n\n  # remove duplicate arcs.\n  arcs = unique.arcs(arcs, nodes, warn = TRUE)\n\n  # check there are no loops among the arcs.\n  loop = (arcs[, \"from\"] == arcs[, \"to\"])\n\n  if (any(loop))\n    stop(\"invalid arcs that are actually loops:\\n\",\n         paste(\"  \", arcs[loop, 1], \"->\", arcs[loop, 2], \"\\n\"))\n\n  return(arcs)\n\n}#CHECK.ARCS\n\n# build a valid whitelist.\nbuild.whitelist = function(whitelist, nodes, data, algo, criterion) {\n\n  if (is.null(whitelist)) {\n\n    # no whitelist, nothing to do.\n    return(NULL)\n\n  }#THEN\n\n  if (is(whitelist, c(\"matrix\", \"data.frame\"))) {\n\n    if (dim(whitelist)[2] != 2)\n      stop(\"whitelist must have two columns.\")\n\n    if (is.data.frame(whitelist))\n      whitelist = as.matrix(cbind(as.character(whitelist[, 1]),\n        as.character(whitelist[, 2])))\n\n  }#THEN\n  else if (is.character(whitelist)) {\n\n    if (length(whitelist) != 2)\n      stop(\"whitelist must have two columns.\")\n\n    whitelist = matrix(whitelist, ncol = 2, byrow = TRUE)\n\n  }#THEN\n  else {\n\n    stop(\"whitelist must be a matrix or data.frame with two columns.\")\n\n  }#ELSE\n\n  # drop duplicate rows.\n  whitelist = unique.arcs(whitelist, nodes, warn = TRUE)\n  # add column names for easy reference.\n  colnames(whitelist) = c(\"from\", \"to\")\n\n  # check all the names in the whitelist against the column names of x.\n  if (any(unique(as.vector(whitelist)) %!in% nodes))\n    stop(\"unknown node label present in the whitelist.\")\n  # check that whitelisted arcs do not violate parametric assumptions.\n  whitelist = check.arcs.against.assumptions(whitelist, data, criterion)\n\n  if (algo %in% score.based.algorithms) {\n\n    # the whitelist should contain only directed arcs; extend the implied CPDAG\n    # instead of picking arc directions at random to avoid loops.\n    whitelist = cpdag.arc.extension(whitelist, nodes = nodes)\n\n  }#THEN\n  else if (algo %in% mim.based.algorithms) {\n\n    # all arcs in the whitelist are treated as undirected, because these\n    # algorithms operate in the space of undirected graphs.\n    whitelist = unique.arcs(arcs.rbind(whitelist, whitelist,\n                  reverse2 = TRUE), nodes)\n\n  }#THEN\n\n  # if the whitelist itself contains cycles, no acyclic graph\n  # can be learned.\n  if (!is.acyclic(whitelist, nodes = nodes,\n         directed = (algo %in% c(constraint.based.algorithms, \"aracne\"))))\n    stop(\"this whitelist does not allow an acyclic graph.\")\n\n  return(whitelist)\n\n}#BUILD.WHITELIST\n\ncheck.arcs.against.assumptions = function(arcs, data, criterion) {\n\n  if (criterion %in% c(available.mixedcg.tests, available.mixedcg.scores)) {\n\n    # arcs cannot point from continuous nodes to discrete nodes.\n    if (is.null(arcs)) {\n\n      arcs = .Call(\"cg_banned_arcs\",\n                   nodes = names(data),\n                   data = data)\n    }#THEN\n    else {\n\n      arcs = .Call(\"arcs_cg_assumptions\",\n                   arcs = arcs,\n                   nodes = names(data),\n                   data = data)\n\n    }#ELSE\n\n  }#THEN\n\n  return(arcs)\n\n}#CHECK.ARCS.AGAINST.ASSUMPTIONS\n\n# build a valid blacklist.\nbuild.blacklist = function(blacklist, whitelist, nodes, algo) {\n\n  if (!is.null(blacklist)) {\n\n    if (is(blacklist, c(\"matrix\", \"data.frame\"))) {\n\n      if (dim(blacklist)[2] != 2)\n        stop(\"blacklist must have two columns.\")\n\n      if (is.data.frame(blacklist))\n        blacklist = as.matrix(cbind(as.character(blacklist[, 1]),\n          as.character(blacklist[, 2])))\n\n    }#THEN\n    else if (is.character(blacklist)) {\n\n      if (length(blacklist) != 2)\n        stop(\"blacklist must have two columns.\")\n\n      blacklist = matrix(blacklist, ncol = 2, byrow = TRUE)\n\n    }#THEN\n    else {\n\n      stop(\"blacklist must be a matrix or data.frame with two columns.\")\n\n    }#ELSE\n\n    # check all the names in the blacklist against the column names of x.\n    if (any(unique(as.vector(blacklist)) %!in% nodes))\n      stop(\"unknown node label present in the blacklist.\")\n\n    if (algo %in% mim.based.algorithms) {\n\n      # all arcs in the whitelist are treated as undirected, because these\n      # algorithms operate in the space of undirected graphs.\n      blacklist = arcs.rbind(blacklist, blacklist, reverse2 = TRUE)\n\n    }#THEN\n\n    # drop duplicate rows.\n    blacklist = unique.arcs(blacklist, nodes)\n\n  }#THEN\n\n  # update blacklist to agree with whitelist.\n  # NOTE: whitelist and blacklist relationship is the same as hosts.allow\n  # and hosts.deny.\n  if (!is.null(whitelist)) {\n\n    # if x -> y is whitelisted but y -> x is not, it is to be blacklisted.\n    to.add = apply(whitelist, 1, function(x)\n               is.whitelisted(whitelist, x[c(2, 1)]))\n    blacklist = arcs.rbind(blacklist, whitelist[!to.add, c(2, 1)])\n\n    # if x -> y is whitelisted, it is to be removed from the blacklist.\n    if (!is.null(blacklist)) {\n\n      blacklist = blacklist[!apply(blacklist, 1,\n        function(x){ is.whitelisted(whitelist, x) }),]\n\n      # also drop duplicate rows.\n      blacklist = unique.arcs(matrix(blacklist, ncol = 2, byrow = FALSE), nodes)\n\n    }#THEN\n\n  }#THEN\n\n  # set the column names.\n  if (!is.null(blacklist))\n    colnames(blacklist) = c(\"from\", \"to\")\n\n  return(blacklist)\n\n}#BUILD.BLACKLIST\n\n# check the list of networks passed to custom.strength().\ncheck.customlist = function(custom, nodes) {\n\n  # check\n  if (!is(custom, \"list\"))\n    stop(\"networks must be a list of objects of class 'bn' or of arc sets.\")\n  if(!all(sapply(custom, function(x) { is(x, \"bn\") || is(x, \"matrix\") })))\n    stop(\"x must be a list of objects of class 'bn' or of arc sets.\")\n\n  validate = function(custom, nodes) {\n\n    if (is(custom, \"bn\")) {\n\n      check.nodes(names(custom$nodes), graph = nodes, min.nodes = length(nodes),\n        max.nodes = length(nodes))\n\n    }\n    else if (is(custom, \"matrix\")) {\n\n      check.arcs(arcs = custom, nodes = nodes)\n\n    }#THEN\n    else {\n\n      stop(\"x must be a list of objects of class 'bn' or of arc sets.\")\n\n    }\n\n  return(TRUE)\n\n  }#VALIDATE\n\n  if (!all(sapply(custom, validate, nodes = nodes)))\n    stop(\"x must be a list of objects of class 'bn' or of arc sets.\")\n\n}#CHECK.CUSTOMLIST\n\n# check score labels.\ncheck.score = function(score, data) {\n\n  # check which type of data we are dealing with.\n  type = data.type(data)\n\n  if (!is.null(score)) {\n\n    # check it's a single character string.\n    check.string(score)\n    # check the score/test label.\n    if (score %!in% available.scores)\n      stop(\"valid scores are:\\n\",\n           sprintf(\"    %-15s %s\\n\", names(score.labels), score.labels))\n    # check if it's the right score for the data (discrete, continuous, mixed).\n    if ((type %!in% discrete.data.types) &&\n         (score %in% available.discrete.scores))\n      stop(\"score '\", score, \"' may be used with discrete data only.\")\n    if ((type != \"continuous\") && (score %in% available.continuous.scores))\n      stop(\"score '\", score, \"' may be used with continuous data only.\")\n    if ((type != \"mixed-cg\") && (score %in% available.mixedcg.scores))\n      stop(\"score '\", score, \"' may be used with a mixture of continuous and discrete data only.\")\n\n    return(score)\n\n  }#THEN\n  else {\n\n    # warn about ordinal data modelled as unordered categorical ones.\n    if (type %in% c(\"ordered\", \"mixed-do\"))\n      warning(\"no score is available for ordinal data, disregarding the ordering of the levels.\")\n\n    if (type %in% discrete.data.types)\n      return(\"bic\")\n    else if (type == \"continuous\")\n      return(\"bic-g\")\n    else if (type == \"mixed-cg\")\n      return(\"bic-cg\")\n\n  }#ELSE\n\n}#CHECK.SCORE\n\n# check whether a score is score equivalent.\nis.score.equivalent = function(score, nodes, extra) {\n\n  # log-likelihood for discrete and Gaussian data is always score equivalent.\n  if (score %in% c(\"loglik\", \"loglik-g\"))\n    return(TRUE)\n  # same with AIC and BIC.\n  if (score %in% c(\"aic\", \"aic-g\", \"bic\", \"bic-g\"))\n    return(TRUE)\n  # BDe and BGe are score equivalent if they have uniform priors (e.g. BDeu and BGeu).\n  else if ((score %in% c(\"bde\", \"bge\")) && (extra$prior == \"uniform\"))\n      return(TRUE)\n\n  # a conservative default.\n  return(FALSE)\n\n}#IS.SCORE.EQUIVALENT\n\n# check whether a score is decomposable.\nis.score.decomposable = function(score, nodes, extra) {\n\n  # Castelo & Siebes prior is not decomposable.\n  if ((score %in% c(\"bde\", \"bge\")) && (extra$prior == \"cs\"))\n    return(FALSE)\n\n  # a sensible default.\n  return(TRUE)\n\n}#IS.SCORE.DECOMPOSABLE\n\n# check test labels.\ncheck.test = function(test, data) {\n\n  # check which type of data we are dealing with.\n  type = data.type(data)\n\n  if (!missing(test) && !is.null(test)) {\n    # check it's a single character string.\n    check.string(test)\n    # check the score/test label.\n    orig.length = unlist(options(\"warning.length\" = 4000))\n    if (test %!in% available.tests)\n      stop(\"valid tests are:\\n\", sprintf(\"    %-15s %s\\n\",\n           names(test.labels), test.labels))\n    # check if it's the right test for the data (discrete, continuous).\n    if ((type != \"ordered\") && (test %in% available.ordinal.tests))\n      stop(\"test '\", test, \"' may be used with ordinal data only.\")\n    if ((type %!in% discrete.data.types) && (test %in% available.discrete.tests))\n      stop(\"test '\", test, \"' may be used with continuous data only.\")\n    if ((type != \"continuous\") && (test %in% available.continuous.tests))\n      stop(\"test '\", test, \"' may be used with continuous data only.\")\n    if ((type != \"mixed-cg\") && (test %in% available.mixedcg.tests))\n      stop(\"test '\", test, \"' may be used with a mixture of continuous and discrete data only.\")\n    options(\"warning.length\" = orig.length)\n\n    return(test)\n\n  }#THEN\n  else {\n\n    if (type == \"ordered\")\n      return(\"jt\")\n    else if (type %in% c(\"factor\", \"mixed-do\"))\n      return(\"mi\")\n    else if (type == \"continuous\")\n      return(\"cor\")\n    else if (type == \"mixed-cg\")\n      return(\"mi-cg\")\n\n  }#ELSE\n\n}#CHECK.TEST\n\ncheck.criterion = function(criterion, data) {\n\n  # check it's a single character string.\n  check.string(criterion)\n  # check criterion's label.\n  if (criterion %in% available.tests)\n    criterion = check.test(criterion, data)\n  else if (criterion %in% available.scores)\n    criterion = check.score(criterion, data)\n  else\n    stop(\"valid tests are:\\n\",\n         sprintf(\"    %-15s %s\\n\", names(test.labels), test.labels),\n         \"  valid scores are:\\n\",\n         sprintf(\"    %-15s %s\\n\", names(score.labels), score.labels))\n\n  return(criterion)\n\n}#CHECK.CRITERION\n\n# check loss functions' labels.\ncheck.loss = function(loss, data, bn) {\n\n  # check which type of data we are dealing with.\n  type = data.type(data)\n\n  if (!is.null(loss)) {\n\n    # check it's a single character string.\n    check.string(loss)\n    # check the score/test label.\n    if (loss %!in% loss.functions)\n      stop(\"valid loss functions are:\\n\",\n           sprintf(\"    %-15s %s\\n\", names(loss.labels), loss.labels))\n    if ((type %!in% discrete.data.types) && (loss %in% discrete.loss.functions))\n      stop(\"loss function '\", loss, \"' may be used with discrete data only.\")\n    if ((type != \"continuous\") && (loss %in% continuous.loss.functions))\n      stop(\"loss function '\", loss, \"' may be used with continuous data only.\")\n    if ((type != \"mixed-cg\") && (loss %in% mixedcg.loss.functions))\n      stop(\"loss function '\", loss, \"' may be used with a mixture of continuous and discrete data only.\")\n\n    return(loss)\n\n  }#THEN\n  else {\n\n    if ((is.character(bn) && (bn %in% classifiers)) ||\n         is(bn, c(\"bn.naive\", \"bn.tan\")))\n      return(\"pred\")\n    if (type %in% discrete.data.types)\n      return(\"logl\")\n    else if (type == \"continuous\")\n      return(\"logl-g\")\n    else if (type == \"mixed-cg\")\n      return(\"logl-cg\")\n\n  }#ELSE\n\n}#CHECK.LOSS\n\n# check the method used to fit the parameters of the network.\ncheck.fitting.method = function(method, data) {\n\n  # check which type of data we are dealing with.\n  type = data.type(data)\n\n  if (!is.null(method)) {\n\n    # check it's a single character string.\n    check.string(method)\n    # check the score/test label.\n    if (method %!in% available.fitting.methods)\n      stop(\"valid fitting methods are:\\n\",\n           sprintf(\"    %-15s %s\\n\", names(fitting.labels), fitting.labels))\n    # bayesian parameter estimation is implemented only for discrete data.\n    if ((type %in% c(\"continuous\", \"mixed-cg\")) && (method == \"bayes\"))\n      stop(\"Bayesian parameter estimation for (conditional) Gaussian Bayesian networks is not implemented.\")\n\n    return(method)\n\n  }#THEN\n  else {\n\n    return(\"mle\")\n\n  }#ELSE\n\n}#CHECK.FITTING.METHOD\n\n# check the method used for prediction.\ncheck.prediction.method = function(method, data) {\n\n  if (!is.null(method)) {\n\n    # check it's a single character string.\n    check.string(method)\n    # check the score/test label.\n    if (method %!in% available.prediction.methods)\n      stop(\"valid prediction methods are:\\n\",\n        sprintf(\"    %-15s %s\\n\", names(prediction.labels), prediction.labels))\n\n    return(method)\n\n  }#THEN\n  else {\n\n    return(\"parents\")\n\n  }#ELSE\n\n}#CHECK.PREDICTION.METHOD\n\n# check the method used to discretize the data.\ncheck.discretization.method = function(method) {\n\n  if (!is.null(method)) {\n\n    # check it's a single character string.\n    check.string(method)\n    # check the score/test label.\n    if (method %!in% available.discretization.methods)\n      stop(\"valid discretization methods are:\\n\",\n           sprintf(\"    %-15s %s\\n\", names(discretization.labels),\n                   discretization.labels))\n\n    return(method)\n\n  }#THEN\n  else {\n\n      return(\"quantile\")\n\n  }#ELSE\n\n}#CHECK.DISCRETIZATION.METHOD\n\n# check the estimator for the mutual information.\ncheck.mi.estimator = function(estimator, data) {\n\n  # check which type of data we are dealing with.\n  type = data.type(data)\n\n  if (!is.null(estimator)) {\n\n    # check it's a single character string.\n    check.string(estimator)\n    # check the score/estimator label.\n    if (estimator %!in% available.mi)\n      stop(\"valid estimators are:\\n\",\n           sprintf(\"    %-15s %s\\n\", names(mi.estimator.labels),\n                   mi.estimator.labels))\n    # check if it's the right estimator for the data (discrete, continuous).\n    if ((type %!in% discrete.data.types) &&\n        (estimator %in% available.discrete.mi))\n      stop(\"estimator '\", estimator, \"' may be used with discrete data only.\")\n    if ((type != \"continuous\") && (estimator %in% available.continuous.mi))\n      stop(\"estimator '\", estimator, \"' may be used with continuous data only.\")\n\n    return(estimator)\n\n  }#THEN\n  else {\n\n    if (type %in% discrete.data.types)\n      return(\"mi\")\n    else\n      return(\"mi-g\")\n\n  }#ELSE\n\n}#CHECK.MI.ESTIMATOR\n\n# is the data of a particular type?\ndata.type = function(data) {\n\n  .Call(\"data_type\",\n        data = data)\n\n}#DATA.TYPE\n\n# there are missing data?\nmissing.data = function(data) {\n\n  !all(complete.cases(data))\n\n}#MISSING.DATA\n\n# check the imaginary sample size.\ncheck.iss = function(iss, network, data) {\n\n  # check which type of data we are dealing with.\n  type = data.type(data)\n\n  if (!is.null(iss)) {\n\n    # validate the imaginary sample size.\n    if (!is.positive(iss) || (iss < 1))\n      stop(\"the imaginary sample size must be a numeric value greater than 1.\")\n    # if iss = 1 the bge is NaN, if iss = 2 and phi = \"heckerman\" the\n    # computation stops with the following error:\n    # Error in solve.default(phi[A, A]) :\n    #   Lapack routine dgesv: system is exactly singular\n    if((type == \"continuous\") && (iss < 3))\n      stop(\"the imaginary sample size must be a numeric value greater than 3.\")\n\n  }#THEN\n  else {\n\n    # check whether there is an imaginary sample size stored in the bn object;\n    # otherwise use a the de facto standard value of 10.\n    if (!is.null(network$learning$args$iss))\n      iss = network$learning$args$iss\n    else\n      iss = 10\n\n  }#ELSE\n\n  # coerce iss to integer.\n  return(as.integer(iss))\n\n}#CHECK.ISS\n\n# check the phi defintion to be used in the bge score.\ncheck.phi = function(phi, network, data) {\n\n  if (!is.null(phi)) {\n\n    if (phi %!in% c(\"heckerman\", \"bottcher\"))\n      stop(\"unknown phi definition, should be either 'heckerman' or 'bottcher'.\")\n\n  }#THEN\n  else {\n\n    # check if there is an phi definition stored in the bn object;\n    # otherwise use the one by heckerman.\n    if (!is.null(network$learning$args$phi))\n      phi = network$learning$args$phi\n    else\n      phi = \"heckerman\"\n\n  }#ELSE\n\n  return(phi)\n\n}#CHECK.PHI\n\n# check the experimental data list.\ncheck.experimental = function(exp, network, data) {\n\n  if (!is.null(exp)) {\n\n    if (!is.list(exp))\n      stop(\"experimental data must be specified via a list of indexes.\")\n    if (any(names(exp) %!in% names(data)) || (length(names(exp)) == 0))\n      stop(\"unkown variables specified in the experimental data list.\")\n    for (var in names(exp)) {\n\n      if (!is.positive.vector(exp[[var]]))\n        stop(\"indexes of experimental data must be positive integer numbers.\")\n      if (any(duplicated(exp[[var]])))\n        stop(\"duplicated indexes for experimental data.\")\n      if (any(exp[[var]] > length(data[, var])))\n        stop(\"out of bounds indexes for experimental data.\")\n\n      # just kill empty elements.\n      if (length(exp[[var]]) == 0)\n        exp[[var]] = NULL\n      # also, convert evetything to integers to make things simpler at the\n      # C level.\n      exp[[var]] = as.integer(exp[[var]])\n\n    }#FOR\n\n  }#THEN\n  else {\n\n    # check whether there is a list stored in the bn object; if no experimental\n    # data is specified, return an empty list (which is the same as using the\n    # plain BDe score).\n    if (!is.null(network$learning$args$exp))\n      exp = network$learning$args$exp\n    else\n      exp = structure(vector(ncol(data), mode = \"list\"), names = names(data))\n\n  }#ELSE\n\n  return(exp)\n\n}#CHECK.EXPERIMENTAL\n\n# check the penalty used in AIC and BIC.\ncheck.penalty = function(k, network, data, score) {\n\n  if (!is.null(k)) {\n\n    # validate the penalty weight.\n    if (!is.positive(k))\n      stop(\"the penalty weight must be a positive numeric value.\")\n\n  }#THEN\n  else {\n\n    # check whether there is a penalization coefficient stored in the bn object,\n    # use the default for the score function otherwise.\n    if (!is.null(network$learning$args$k) && (score == network$learning$test))\n      k = network$learning$args$k\n    else\n      k = ifelse((score %in% c(\"aic\", \"aic-g\")), 1, log(nrow(data))/2)\n\n  }#ELSE\n\n  return(k)\n\n}#CHECK.PENALTY\n\n# sanitize prior distributions over the graph space.\ncheck.graph.prior = function(prior, network) {\n\n  if (is.null(prior)) {\n\n    # check whether there is a graph prior stored in the bn object, use the\n    # uniform one otherwise.\n    if (!is.null(network$learning$args$prior))\n      prior = network$learning$args$prior\n    else\n      prior = \"uniform\"\n\n  }#THEN\n  else {\n\n    # check whether prior is a string.\n    check.string(prior)\n    # check whether the label matches a known prior.\n    if (prior %!in% prior.distributions)\n      stop(\"valid prior distributions are: \",\n        paste(prior.distributions, collapse = \" \"), \".\")\n\n  }#ELSE\n\n  return(prior)\n\n}#CHECK.GRAPH.PRIOR\n\n# check the sparsity parameter of the prior distribution over the graph space.\ncheck.graph.sparsity = function(beta, prior, network, data, learning = FALSE) {\n\n  default.beta =\n    list(\"uniform\" = NULL, \"vsp\" = 1/ncol(data),\n      \"cs\" = cs.completed.prior(data.frame(character(0), character(0),\n             numeric(0)), names(data)))\n\n  if (is.null(beta)) {\n\n    # check whether there is a graph prior stored in the bn object, use the\n    # uniform one otherwise.\n    if (!is.null(network$learning$args$prior))\n      beta = network$learning$args$beta\n    else\n      beta = default.beta[[prior]]\n\n  }#THEN\n  else {\n\n    if (prior == \"uniform\") {\n\n      warning(\"unused argument beta.\")\n      beta = NULL\n\n    }#THEN\n    else if (prior == \"vsp\") {\n\n      if (!is.probability(beta) || (beta >= 1))\n       stop(\"beta must be a probability smaller than 1.\")\n\n    }#THEN\n    else if (prior == \"cs\") {\n\n      # arcs' prior probabilities should be provided in a data frame.\n      if (!is.data.frame(beta) || (ncol(beta) != 3) ||\n          !identical(colnames(beta), c(\"from\", \"to\", \"prob\")))\n        stop(\"beta must be a data frame with three colums: 'from', 'to' and 'prob'.\")\n      # the probs cloumns must contain only probabilities.\n      if (!is.probability.vector(beta$prob))\n        stop(\"arcs prior must contain only probabilities.\")\n      # check that the first two columns contain only valid arcs.\n      check.arcs(beta[, c(\"from\", \"to\")], nodes = names(data))\n\n      # complete the user-specified prior.\n      beta = cs.completed.prior(beta, names(data), learning)\n\n    }#THEN\n\n  }#ELSE\n\n  return(beta)\n\n}#CHECK.GRAPH.SPARSITY\n\ncheck.maxp = function(maxp, data) {\n\n  if (is.null(maxp)) {\n\n    maxp = Inf\n\n  }#THEN\n  else if (!isTRUE(all.equal(maxp, Inf))) {\n\n    if (!is.positive.integer(maxp))\n      stop(\"maxp must be a positive number.\")\n    if (maxp >= ncol(data))\n      warning(\"maximum number of parents should be lower than the number of nodes, the limit will be ignored.\")\n\n  }#ELSE\n\n  return(as.numeric(maxp))\n\n}#CHECK.MAXP\n\n# sanitize the extra arguments passed to the network scores.\ncheck.score.args = function(score, network, data, extra.args, learning = FALSE) {\n\n  # check the imaginary sample size.\n  if (score %in% c(\"bde\", \"bdes\", \"mbde\", \"bge\"))\n    extra.args$iss = check.iss(iss = extra.args$iss,\n      network = network, data = data)\n\n  # check the graph prior distribution.\n  if (score %in% c(\"bde\", \"bge\"))\n    extra.args$prior = check.graph.prior(prior = extra.args$prior,\n      network = network)\n\n  # check the sparsity parameter of the graph prior distribution.\n  if (score %in% c(\"bde\", \"bge\"))\n    extra.args$beta = check.graph.sparsity(beta = extra.args$beta,\n      prior = extra.args$prior, network = network, data = data,\n      learning = learning)\n\n  # check the list of the experimental observations in the data set.\n  if (score == \"mbde\")\n    extra.args$exp = check.experimental(exp = extra.args$exp,\n      network = network, data = data)\n\n  # check the likelihood penalty.\n  if (score %in% c(\"aic\", \"bic\", \"aic-g\", \"bic-g\", \"aic-cg\", \"bic-cg\"))\n    extra.args$k = check.penalty(k = extra.args$k, network = network,\n      data = data, score = score)\n\n  # check phi estimator.\n  if (score == \"bge\")\n    extra.args$phi = check.phi(phi = extra.args$phi,\n      network = network, data = data)\n\n  check.unused.args(extra.args, score.extra.args[[score]])\n\n  return(extra.args)\n\n}#CHECK.SCORE.ARGS\n\n# sanitize the extra arguments passed to the random graph generation algorithms.\ncheck.graph.generation.args = function(method, nodes, extra.args) {\n\n  if (method == \"ordered\") {\n\n    if (!is.null(extra.args$prob)) {\n\n      # prob must be numeric.\n      if (!is.probability(extra.args$prob))\n        stop(\"the branching probability must be a numeric value in [0,1].\")\n\n    }#THEN\n    else {\n\n      # this default produces graphs with about the same number of\n      # arcs as there are nodes.\n      extra.args$prob = 2 / (length(nodes) - 1)\n\n    }#ELSE\n\n  }#THEN\n  else if (method %in% c(\"ic-dag\", \"melancon\")) {\n\n    if (!is.null(extra.args$every)) {\n\n      if (!is.positive(extra.args$every))\n        stop(\"'every' must be a positive integer number.\")\n\n    }#THEN\n    else {\n\n      extra.args$every = 1\n\n    }#ELSE\n\n    if (!is.null(extra.args$burn.in)) {\n\n      if (!is.positive(extra.args$burn.in))\n        stop(\"the burn in length must be a positive integer number.\")\n\n    }#THEN\n    else {\n\n      extra.args$burn.in = 6 * length(nodes)^2\n\n    }#ELSE\n\n    if (!is.null(extra.args$max.in.degree)) {\n\n      if (!is.positive.integer(extra.args$max.in.degree))\n        stop(\"the maximum in-degree must be a positive integer number.\")\n\n      if (extra.args$max.in.degree >= length(nodes)) {\n\n        warning(\"a node cannot have an in-degree greater or equal to the number of nodes in the graph.\")\n        warning(\"the condition on the in-degree will be ignored.\")\n\n      }#THEN\n\n    }#THEN\n    else {\n\n      extra.args$max.in.degree = Inf\n\n    }#ELSE\n\n    if (!is.null(extra.args$max.out.degree)) {\n\n      if (!is.positive.integer(extra.args$max.out.degree))\n        stop(\"the maximum out-degree must be a positive integer number.\")\n\n      if (extra.args$max.out.degree >= length(nodes)) {\n\n        warning(\"a node cannot have an out-degree greater or equal to the number of nodes in the graph.\")\n        warning(\"the condition on the out-degree will be ignored.\")\n\n      }#THEN\n\n    }#THEN\n    else {\n\n      extra.args$max.out.degree = Inf\n\n    }#ELSE\n\n    if (!is.null(extra.args$max.degree)) {\n\n      if (!is.positive.integer(extra.args$max.degree))\n        stop(\"the maximum out-degree must be a positive integer number.\")\n\n      if (is.finite(extra.args$max.in.degree) &&\n          extra.args$max.in.degree > extra.args$max.degree)\n        stop(\"the maximun in-degree must be lesser or equal to the maximum degree.\")\n\n      if (is.finite(extra.args$max.out.degree) &&\n          extra.args$max.out.degree > extra.args$max.degree)\n        stop(\"the maximun out-degree must be lesser or equal to the maximum degree.\")\n\n      if (extra.args$max.degree >= length(nodes)) {\n\n        warning(\"a node cannot have a degree greater or equal to the number of nodes in the graph.\")\n        warning(\"the condition on the degree will be ignored.\")\n\n      }#THEN\n\n    }#THEN\n    else {\n\n      extra.args$max.degree = Inf\n\n    }#ELSE\n\n  }#THEN\n\n  check.unused.args(extra.args, graph.generation.extra.args[[method]])\n\n  return(extra.args)\n\n}#CHECK.GRAPH.GENERATION.ARGS\n\n# check bootstrap arguments (when they are passed as variable length args).\ncheck.bootstrap.args = function(extra.args, network, data) {\n\n  # check the number of bootstrap replicates.\n  extra.args$R = check.replicates(extra.args$R)\n  # check the size of each bootstrap sample.\n  extra.args$m = check.bootsize(extra.args$m, data)\n  # check the learning algorithm.\n  algorithm = check.learning.algorithm(extra.args[[\"algorithm\"]], bn = network)\n  # check the extra arguments for the learning algorithm.\n  algorithm.args = check.learning.algorithm.args(extra.args[[\"algorithm.args\"]],\n                     algorithm = algorithm, bn = network)\n\n  extra.args[[\"algorithm\"]] = algorithm\n  extra.args[[\"algorithm.args\"]] = algorithm.args\n\n  # remap additional arguments used in hybrid algorithms.\n  if (algorithm %in% hybrid.algorithms) {\n\n    # there's no need to sanitize these parameters, it's done either in\n    # bnlearn() or in greedy.search() already.\n    if (is.null(extra.args[[\"algorithm.args\"]]$restrict))\n      extra.args[[\"algorithm.args\"]]$restrict = network$learning$restrict\n    if (is.null(extra.args[[\"algorithm.args\"]]$maximize))\n      extra.args[[\"algorithm.args\"]]$maximize = network$learning$maximize\n    if (is.null(extra.args[[\"algorithm.args\"]]$test))\n      extra.args[[\"algorithm.args\"]]$test = network$learning$rstest\n    if (is.null(extra.args[[\"algorithm.args\"]]$score))\n      extra.args[[\"algorithm.args\"]]$score = network$learning$maxscore\n\n  }#THEN\n\n  # warn about unused arguments.\n  check.unused.args(extra.args, c(\"R\", \"m\", \"algorithm\", \"algorithm.args\"))\n\n  return(extra.args)\n\n}#CHECK.BOOTSTRAP.ARGS\n\n# sanitize the extra arguments passed to the conditional probability algorithms.\ncheck.cpq.args = function(fitted, extra.args, method, action) {\n\n  if (method %in% c(\"ls\", \"lw\")) {\n\n    if (!is.null(extra.args$n)) {\n\n      if (!is.positive.integer(extra.args$n))\n        stop(\"the number of observations to be sampled must be a positive integer number.\")\n\n    }#THEN\n    else {\n\n      # this is a rule of thumb, the error of the estimate has no closed-form\n      # expression (Koller & Friedman).\n      if (!is(fitted, \"bn.fit.gnet\"))\n        extra.args$n = 5000 * max(1, round(log10(nparams.fitted(fitted))))\n      else\n        extra.args$n = 500 * nparams.fitted(fitted)\n\n    }#ELSE\n\n    if (!is.null(extra.args$batch)) {\n\n      if ((action == \"cpdist\") && (method == \"lw\")) {\n\n        extra.args$batch = NULL\n        warning(\" 'batch' will be ignored for speed and memory efficience.\")\n\n      }#THEN\n      else {\n\n        if (!is.positive.integer(extra.args$batch))\n          stop(\"the number of observations to be sampled must be a positive integer number.\")\n\n        if (extra.args$batch > extra.args$n) {\n\n          warning(\"cannot generate a batch bigger than the whole generated data set.\")\n          warning(\"batch size will be ignored.\")\n\n        }#THEN\n\n      }#ELSE\n\n    }#THEN\n    else {\n\n      # perform small simulations in a single batch, and split larger ones.\n      extra.args$batch = min(extra.args$n, 10^4)\n\n    }#ELSE\n\n    if (!is.null(extra.args$query.nodes)) {\n\n      check.nodes(extra.args$query.nodes, graph = fitted)\n\n    }#THEN\n\n  }#THEN\n\n  # warn about unused arguments.\n  check.unused.args(extra.args, cpq.extra.args[[method]])\n\n  return(extra.args)\n\n}#CHECK.CPQ.ARGS\n\n# sanitize the extra arguments passed to loss functions.\ncheck.loss.args = function(loss, bn, nodes, data, extra.args) {\n\n  valid.args = loss.extra.args[[loss]]\n\n  if (loss %in% c(\"pred\", \"pred-lw\", \"cor\", \"cor-lw\", \"mse\", \"mse-lw\")) {\n\n    if (!is.null(extra.args$target)) {\n\n      if (!is.string(extra.args$target) || (extra.args$target %!in% nodes))\n        stop(\"target node must be a single, valid node label for the network.\")\n\n    }#THEN\n    else {\n\n      # the target node is obvious for classifiers.\n      if (is(bn, c(\"bn.naive\", \"bn.tan\"))) {\n\n        if (is(bn, \"bn\"))\n          extra.args$target = bn$learning$args$training\n        else\n          extra.args$target = attr(bn, \"training\")\n\n      }#THEN\n      else {\n\n        stop(\"missing target node for which to compute the prediction error.\")\n\n      }#ELSE\n\n    }#ELSE\n\n    # check the prior distribution.\n    if ((bn %in% classifiers) || is(bn, c(\"bn.naive\", \"bn.tan\"))) {\n\n      extra.args$prior = check.classifier.prior(extra.args$prior, data[, extra.args$target])\n      valid.args = c(valid.args, \"prior\")\n\n    }#THEN\n\n  }#THEN\n\n  if (loss %in% c(\"pred-lw\", \"cor-lw\", \"mse-lw\")) {\n\n    # number of particles for likelihood weighting.\n    if (!is.null(extra.args$n)) {\n\n      if (!is.positive.integer(extra.args$n))\n        stop(\"the number of observations to be sampled must be a positive integer number.\")\n\n    }#THEN\n    else {\n\n      extra.args$n = 500\n\n    }#ELSE\n\n    # which nodes to predict from.\n    if (!is.null(extra.args$from))\n      check.nodes(extra.args$from, graph = names(data), min.nodes = 1)\n    else\n      extra.args$from = setdiff(names(data), extra.args$target)\n\n  }#THEN\n\n  # warn about unused arguments.\n  check.unused.args(extra.args, valid.args)\n\n  return(extra.args)\n\n}#CHECK.LOSS.ARGS\n\n# sanitize the extra arguments passed to fitting functions.\ncheck.fitting.args = function(method, network, data, extra.args) {\n\n  if (method == \"bayes\") {\n\n    # check the imaginary sample size.\n    extra.args$iss = check.iss(iss = extra.args$iss,\n      network = network, data = data)\n\n  }#THEN\n\n  # warn about unused arguments.\n  check.unused.args(extra.args, fitting.extra.args[[method]])\n\n  return(extra.args)\n\n}#CHECK.FITTING.ARGS\n\n# sanitize the extra arguments passed to discretization methods.\ncheck.discretization.args = function(method, data, breaks, extra.args) {\n\n  # check which type of data we are dealing with.\n  type = data.type(data)\n\n  if (method == \"hartemink\") {\n\n    if (type %in% discrete.data.types) {\n\n      extra.args$ibreaks = nlevels(data[, 1])\n      warning(\"data are already discrete, 'ibreaks' and 'idisc' are ignored.\")\n\n    }#THEN\n    else {\n\n      if (!is.null(extra.args$idisc)) {\n\n        idisc = extra.args$idisc\n\n        # check it's a single character string.\n        check.string(idisc)\n        # check the score/test label.\n        other.methods = available.discretization.methods[available.discretization.methods != \"hartemink\"]\n        if (idisc %!in% other.methods)\n          stop(\"valid initial discretization methods are:\\n\",\n               sprintf(\"    %-15s %s\\n\", other.methods,\n                       discretization.labels[other.methods]))\n\n      }#THEN\n      else {\n\n        # default to quantile discretization as per Hartemink's recommendation.\n        extra.args$idisc = \"quantile\"\n\n      }#ELSE\n\n      if (!is.null(extra.args$ibreaks)) {\n\n        if (!is.positive.integer(extra.args$ibreaks))\n          stop(\"the number of initial breaks must be a positive integer number.\")\n        if (extra.args$ibreaks < breaks)\n          stop(\"insufficient number of levels, at least \", breaks, \" required.\")\n\n      }#THEN\n      else {\n\n        ndata = nrow(data)\n\n        if (ndata > 500)\n          extra.args$ibreaks = 100\n        else if (ndata > 100)\n          extra.args$ibreaks = 50\n        else if (ndata > 50)\n          extra.args$ibreaks = 20\n        else if (ndata > 10)\n          extra.args$ibreaks = 10\n        else\n          extra.args$ibreaks = ndata\n\n      }#ELSE\n\n    }#ELSE\n\n  }#THEN\n\n  # warn about unused arguments.\n  check.unused.args(extra.args, discretization.extra.args[[method]])\n\n  return(extra.args)\n\n}#CHECK.DISCRETIZATION.ARGS\n\n# sanitize the extra arguments passed to Bayesian classifiers.\ncheck.classifier.args = function(method, data, training, explanatory,\n    extra.args) {\n\n  if (method == \"tree.bayes\") {\n\n    # check the label of the mutual information estimator.\n    extra.args$estimator = check.mi.estimator(extra.args$estimator, data)\n\n    # check the node to use the root of the tree (if not specified pick the first\n    # explanatory variable assuming natural ordering).\n    if (!is.null(extra.args$root))\n      check.nodes(extra.args$root, graph = explanatory, max.nodes = 1)\n    else\n      extra.args$root = explanatory[1]\n\n  }#THEN\n\n  return(extra.args)\n\n}#CHECK.CLASSIFIER.ARGS\n\n# warn about unused arguments.\ncheck.unused.args = function(dots, used.args) {\n\n  unused.args = (names(dots) %!in% used.args)\n  if (any(unused.args))\n    warning(\"unused argument(s):\", paste0(\" '\", names(dots)[unused.args], \"'\"), \".\")\n\n}#CHECK.UNUSED.ARGS\n\n# take care of meaningless dots arguments in plot functions.\nsanitize.plot.dots = function(dots, meaningless) {\n\n  # warn about them.\n  if (any(names(dots) %in% meaningless))\n    warning(\"arguments \", paste(meaningless, collapse = \", \"),\n      \" will be silently ignored.\")\n  # nuke them from orbit.\n  for (m in meaningless)\n    dots[[m]] = NULL\n\n  return(dots)\n\n}#PROCESS.PLOT.DOTS\n\n# check the the target nominal type I error rate\ncheck.alpha = function(alpha, network = NULL) {\n\n  # check the the target nominal type I error rate\n  if (!missing(alpha) && !is.null(alpha)) {\n\n    # validate alpha.\n    if (!is.probability(alpha))\n      stop(\"alpha must be a numerical value in [0,1].\")\n\n  }#THEN\n  else {\n\n    # check if there is an alpha value stored in the bn object;\n    # otherwise use the usual 0.05 value.\n    if (!is.null(network$learning$args$alpha))\n      alpha = network$learning$args$alpha\n    else\n      alpha = 0.05\n\n  }#ELSE\n\n  return(alpha)\n\n}#CHECK.ALPHA\n\n# check the number of permutation/boostrap samples.\ncheck.B = function(B, criterion) {\n\n  if (criterion %in% resampling.tests) {\n\n    if (!missing(B) && !is.null(B)) {\n\n      if (!is.positive.integer(B))\n        stop(\"the number of permutations/bootstrap replications must be a positive integer number.\")\n\n      B = as.integer(B)\n\n    }#THEN\n    else {\n\n      if (criterion %in% semiparametric.tests)\n        B = 100L\n      else\n        B = 5000L\n\n    }#ELSE\n\n  }#THEN\n  else {\n\n    if (!missing(B) && !is.null(B))\n      warning(\"this test does not require any permutations/bootstrap resampling, ignoring B.\\n\")\n\n    B = NULL\n\n  }#ELSE\n\n  return(B)\n\n}#CHECK.B\n\ncheck.amat = function(amat, nodes) {\n\n  # a node is needed.\n  if (missing(amat))\n    stop(\"no adjacency matrix specified.\")\n  # the adjacency matrix must, well, be a matrix.\n  if (!is(amat, \"matrix\") || (ncol(amat) != nrow(amat)) || (length(dim(amat)) != 2))\n    stop(\"an adjacency matrix must be a 2-dimensional square matrix.\")\n  # check the dimensions against the number of nodes in the graph.\n  if (any(dim(amat) != length(nodes)))\n    stop(\"the dimensions of the adjacency matrix do not agree with the number of nodes in the graph.\")\n  # column names must be valid node labels.\n  if (!is.null(colnames(amat)))\n    if (any(colnames(amat) %!in% nodes))\n      stop(\"node (column label) not present in the graph.\")\n  # column names must be valid node labels.\n  if (!is.null(rownames(amat)))\n    if (any(rownames(amat) %!in% nodes))\n      stop(\"node (row label) not present in the graph.\")\n  # column names must match with row names.\n  if (!is.null(colnames(amat)) && !is.null(rownames(amat))) {\n\n    if (!identical(colnames(amat), rownames(amat)))\n      stop(\"row/column names mismatch in the adjacency matrix.\")\n\n    if (!identical(colnames(amat), nodes) || !identical(rownames(amat), nodes)) {\n\n      warning(\"rearranging the rows/columns of the adjacency matrix.\")\n\n      amat = amat[nodes, nodes, drop = FALSE]\n\n    }#THEN\n\n  }#THEN\n  # make really sure the adjacency matrix is made up of integers.\n  if (storage.mode(amat) != \"integer\")\n    storage.mode(amat) = \"integer\"\n  # check the elements of the matrix.\n  if (!all((amat == 0L) | (amat == 1L)))\n    stop(\"all the elements of an adjacency matrix must be equal to either 0 or 1.\")\n  # no arcs from a node to itself.\n  if(any(diag(amat) != 0))\n    stop(\"the elements on the diagonal must be zero.\")\n\n  return(amat)\n\n}#CHECK.AMAT\n\ncheck.covariance = function(m) {\n\n  # the adjacency matrix must, well, be a matrix.\n  if (!is(m, \"matrix\") || (ncol(m) != nrow(m)) || (length(dim(m)) != 2))\n    stop(\"a covariance matrix must be a 2-dimensional square matrix.\")\n  # check the elements of the matrix.\n  if (!is.numeric(m))\n    stop(\"the elements of a covariance matrix must be real numbres.\")\n  # check whether the matrix is symmetric.\n  if (!is.symmetric(m))\n    stop(\"a covariance matrix must be symmetric.\")\n  # check whether the matrix obeys the Cauchy-Schwarz theorem.\n  if (!is.cauchy.schwarz(m))\n    stop(\"a covariance matrix must obey the Cauchy-Schwarz theorem.\")\n\n}#CHECK.COVARIANCE\n\n# check logical flags.\ncheck.logical = function(bool) {\n\n  if (!is.logical(bool) || is.na(bool) || (length(bool) != 1)) {\n\n    stop(sprintf(\"%s must be a logical value (TRUE/FALSE).\",\n           deparse(substitute(bool))))\n\n  }#THEN\n\n}#CHECK.LOGICAL\n\n# check character strings.\ncheck.string = function(string) {\n\n  if (!is.string(string)) {\n\n    stop(sprintf(\"%s must be a character string.\",\n           deparse(substitute(string))))\n\n  }#THEN\n\n}#CHECK.STRING\n\n# check an object of class bn.\ncheck.bn = function(bn) {\n\n  if (missing(bn))\n    stop(\"an object of class 'bn' is required.\")\n  if (!is(bn, \"bn\")) {\n\n    stop(sprintf(\"%s must be an object of class 'bn'.\",\n           deparse(substitute(bn))))\n\n  }#THEN\n\n}#CHECK.BN\n\n# check two bn's against each other.\nmatch.bn = function(bn1, bn2) {\n\n  # the two networks must have the same node set.\n  nodes1 = names(bn1$nodes)\n  nodes2 = names(bn2$nodes)\n\n  equal = setequal(nodes1, nodes2) && (length(nodes1) == length(nodes2))\n\n  if (!equal)\n    stop(\"the two networks have different node sets.\")\n\n}#MATCH.BN\n\n# check an object of class bn or bn.fit.\ncheck.bn.or.fit = function(bn) {\n\n  if (missing(bn))\n    stop(\"an object of class 'bn' or 'bn.fit' is required.\")\n  if (!is(bn, \"bn\") && !is(bn, \"bn.fit\")) {\n\n    stop(sprintf(\"%s must be an object of class 'bn' or 'bn.fit'.\",\n           deparse(substitute(bn))))\n\n  }#THEN\n\n}#CHECK.BN.OR.FIT\n\n# check an object of class bn.fit.\ncheck.fit = function(bn) {\n\n  if (missing(bn))\n    stop(\"an object of class 'bn.fit' is required.\")\n  if (!is(bn, \"bn.fit\")) {\n\n    stop(sprintf(\"%s must be an object of class 'bn.fit'.\",\n           deparse(substitute(bn))))\n\n  }#THEN\n\n}#CHECK.FIT\n\n# check the structure of a naive Bayes classifier.\ncheck.bn.naive = function(bn) {\n\n  # check whether it's a valid bn/bn.fit object.\n  check.bn.or.fit(bn)\n  # there must be a single root node, check.\n  root = root.leaf.nodes(bn, leaf = FALSE)\n\n  if (length(root) != 1)\n    stop(\"a naive Bayes classifier can have only one root node, the training variable.\")\n\n  # cache the node labels.\n  if (is(bn, \"bn\"))\n    nodes = names(bn$nodes)\n  else\n    nodes = names(bn)\n  # get the explanatory variables.\n  explanatory = nodes[nodes != root]\n  leafs = root.leaf.nodes(bn, leaf = TRUE)\n  # all the explanatory variables must be leaf nodes, check.\n  if (!identical(sort(explanatory), sort(leafs)))\n    stop(\"all the explanatory variables must be leaf nodes.\")\n  # all the explanatory variables must have a single parent, the root node, check.\n  nparents = sapply(explanatory, function(node) { length(parents(bn, node))  })\n\n  if (any(nparents != 1))\n    stop(\"all the explanatory variables must be children of the training variable.\")\n\n}#CHECK.BN.NAIVE\n\n# check the structure of a naive Bayes classifier.\ncheck.bn.tan = function(bn) {\n\n  # check whether it's a valid bn/bn.fit object.\n  check.bn.or.fit(bn)\n  # there must be a single root node, check.\n  root = root.leaf.nodes(bn, leaf = FALSE)\n\n  if (length(root) != 1)\n    stop(\"a naive Bayes classifier can have only one root node, the training variable.\")\n\n  # that root node must be the training variable, check.\n  if (is(bn, \"bn\")) {\n\n    # double check just in case.\n    check.nodes(bn$learning$args$training)\n\n    nodes = names(bn$nodes)\n    training = bn$learning$args$training\n\n  }#THEN\n  else {\n\n    # double check just in case.\n    check.nodes(attr(bn, \"training\"))\n\n    nodes = names(bn)\n    training = attr(bn, \"training\")\n\n  }#ELSE\n\n  if (!identical(training, root))\n    stop(\"the training node is not the only root node in the graph.\")\n\n  # get the explanatory variables.\n  explanatory = nodes[nodes != root]\n  # all the explanatory variables save one must have exactly two parents, check.\n  nparents = sapply(explanatory, function(node) { length(parents(bn, node))  })\n\n  if (!( (length(which(nparents == 2)) == length(explanatory) - 1) && (length(which(nparents == 1)) == 1) ))\n    stop(\"the explanatory variables must form a tree.\")\n\n}#CHECK.BN.TAN\n\n# check an object of class bn.strength.\ncheck.bn.strength = function(strength, nodes) {\n\n  if (missing(strength))\n    stop(\"an object of class 'bn.strength' is required.\")\n  if (!is(strength, \"bn.strength\")) {\n\n    stop(sprintf(\"%s must be an object of class 'bn.strength'.\",\n           deparse(substitute(strength))))\n\n  }#THEN\n  if (ncol(strength) %!in% 3:4)\n    stop(\"objects of class 'bn.strength' must have 3 or 4 columns.\")\n  if (!identical(names(strength), c(\"from\", \"to\", \"strength\")) &&\n      !identical(names(strength), c(\"from\", \"to\", \"strength\", \"direction\")))\n    stop(\"objects of class 'bn.strength' must be data frames with column names \",\n         \"'from', 'to', 'strength' and (optionally) 'direction'.\")\n  if (any(c(\"mode\", \"threshold\") %!in% names(attributes(strength))))\n    stop(\"objects of class 'bn.strength' must have a 'mode' and a 'strength' attribute.\")\n  if (!missing(nodes))\n    check.arcs(strength[, c(\"from\", \"to\"), drop = FALSE], nodes)\n\n}#CHECK.BN.STRENGTH\n\n# sanitize the threshold value.\ncheck.threshold = function(threshold, strength) {\n\n  if (missing(threshold))\n    threshold = attr(strength, \"threshold\")\n  else {\n\n    s = strength[, \"strength\"]\n\n    if (!is.numeric(threshold) || (length(threshold) != 1) || is.nan(threshold))\n      stop(\"the threshold must be a numeric value.\")\n    if ((threshold < min(s)) || (threshold > max(s)))\n      warning(\"the threshold is outside the range of the strength values.\")\n\n  }#ELSE\n\n  return(threshold)\n\n}#CHECK.THRESHOLD\n\n# check parameters related to the random restart functions.\ncheck.restart = function(restart) {\n\n  # set the default value if not specified.\n  if (is.null(restart) || (restart == 0))\n      return(0)\n\n  if (!is.positive.integer(restart))\n    stop(\"the number of random restarts must be a non-negative numeric value.\")\n  else\n    return(restart)\n\n}#CHECK.RESTART\n\ncheck.perturb = function(perturb) {\n\n  # set the default value if not specified.\n  if (is.null(perturb))\n      return(1)\n\n  if (!is.positive.integer(perturb))\n    stop(\"the number of changes at each radom restart must be a non-negative numeric value.\")\n  else\n    return(perturb)\n\n}#CHECK.PERTURB\n\n# check the maximum number of iterations.\ncheck.max.iter = function(max.iter) {\n\n  # set the default value if not specified.\n  if (is.null(max.iter))\n    return(Inf)\n\n  if ((max.iter != Inf) && !is.positive.integer(max.iter))\n    stop(\"the maximum number of iterations must be a positive integer number.\")\n  else\n    return(max.iter)\n\n}#CHECK.MAX.ITER\n\n# check arguments related to the tabu list.\ncheck.tabu = function(tabu) {\n\n  # set the default value if not specified.\n  if (is.null(tabu))\n    return(10)\n\n  if (!is.positive.integer(tabu))\n    stop(\"the length of the tabu list must be a positive integer number.\")\n  else\n    return(tabu)\n\n}#CHECK.TABU\n\ncheck.max.tabu = function(max, tabu) {\n\n  if (is.null(max))\n    return(tabu)\n\n  # check the number of iterations the algorithm can perform without\n  # improving the best network score.\n  if (!is.positive.integer(max))\n    stop(\"the maximum number of iterations without any score improvement must be a positive integer number.\")\n  # the tabu list should be longer than that, otherwise the search can do a\n  # U-turn and return to the local maximum it left before (thus creating an\n  # endless loop).\n  if (max > tabu)\n    stop(\"the maximum number of iterations without any score improvement must not be grater than the length of the tabu list.\")\n\n  return(max)\n\n}#CHECK.MAX.TABU\n\n# check bn metadata against the data it's used with.\ncheck.bn.vs.data = function(bn, data) {\n\n  # check which type of data we are dealing with.\n  type = data.type(data)\n\n  # the number of variables must be the same\n  if (length(names(bn$nodes)) != ncol(data))\n    stop(\"the network and the data have different numbers of variables.\")\n  # the variables must be the same.\n  if (length(setdiff(names(bn$nodes), names(data))) != 0)\n    stop(\"the variables in the data and in the network do not match.\")\n  # data type versus network structure.\n  if (type == \"mixed-cg\")\n    check.arcs.against.assumptions(bn$arcs, data, \"mi-cg\")\n\n}#CHECK.BN.VS.DATA\n\n# check bn.fit metadata against the data it's used with.\ncheck.fit.vs.data = function(fitted, data, subset) {\n\n  fitted.names = names(fitted)\n  # check which type of data we are dealing with.\n  dtype = data.type(data)\n\n  if (missing(subset)) {\n\n    # the number of variables must be the same.\n    if (length(fitted.names) != ncol(data))\n      stop(\"the network and the data have different numbers of variables.\")\n    # the variables must be the same.\n    if (length(setdiff(fitted.names , names(data))) != 0)\n      stop(\"the variables in the data and in the network do not match.\")\n\n    subset = fitted.names\n\n  }#THEN\n  else {\n\n    # the number of variables must not exceed that of the network.\n    if (length(subset) > length(fitted.names))\n      stop(\"the data have more variables than the network.\")\n    # all the variables in the subset must be present in the data.\n    absent = (subset %!in% names(data))\n    if (any(absent))\n      stop(\"required variables '\", paste(subset[absent], collapse = \" \"),\n           \"' are not present in the data.\")\n\n  }#ELSE\n\n  .Call(\"fitted_vs_data\",\n        fitted = fitted,\n        data = data,\n        subset = subset)\n\n}#CHECK.FIT.VS.DATA\n\n# check bn.fit.{d,g}node metadata against the data it's used with.\ncheck.fit.node.vs.data = function(fitted, data) {\n\n  relevant = c(fitted$node, fitted$parents)\n  # check which type of data we are dealing with.\n  type = data.type(data)\n\n  # check whether all relevant nodes are in the data.\n  if (any(relevant %!in% names(data)))\n    stop(\"not all required nodes are present in the data.\")\n  # data type versus network type.\n  if (is(fitted, \"bn.fit.dnode\") && (type == \"continuous\"))\n      stop(\"continuous data and discrete network.\")\n  if (is(fitted, \"bn.fit.gnode\") &&\n      (type %in% discrete.data.types))\n    stop(\"discrete data and continuous network.\")\n  # double-check the levels of the variables against those of the nodes.\n  if (is(fitted, \"bn.fit.dnode\")) {\n\n    for (node in relevant) {\n\n      data.levels = levels(data[, node])\n      if (length(relevant) == 1)\n        node.levels = dimnames(fitted$prob)[[1]]\n      else\n        node.levels = dimnames(fitted$prob)[[node]]\n\n      if(!identical(data.levels, node.levels))\n        stop(\"the levels of node '\", node, \"' do not match the levels of the \",\n             \"corresponding variable in the data.\")\n\n    }#FOR\n\n  }#THEN\n\n}#CHECK.FIT.NODE.VS.DATA\n\n# check a colour identifier (not necessarily a string/integer).\ncheck.colour = function(col) {\n\n  if (identical(tryCatch(col2rgb(col), error = function(x) { FALSE }), FALSE))\n    stop(sprintf(\"%s is not a valid colour identifier.\",\n           deparse(substitute(col))))\n\n}#CHECK.COLOUR\n\n# check the line type identifier.\ncheck.lty = function(lty) {\n\n  lty.strings = c(\"blank\", \"solid\", \"dashed\", \"dotted\", \"dotdash\", \"longdash\",\n                  \"twodash\")\n\n  if ((lty %!in% 0:6) && (lty %!in% lty.strings))\n    stop(sprintf(\"%s is not a valid line type identifier.\",\n           deparse(substitute(lty))))\n\n}#CHECK.LTY\n\n# check the label of a learning algorithm.\ncheck.learning.algorithm = function(algorithm, class = \"all\", bn) {\n\n  ok = character(0)\n\n  if (missing(algorithm) || is.null(algorithm)) {\n\n    # use the one specified by the bn object as the default.\n    if (missing(bn))\n      stop(\"the learning algorithm must be a character string.\")\n    else if (is(bn, \"bn\"))\n      algorithm = bn$learning$algo\n\n  }#THEN\n  else if (!is.string(algorithm))\n    stop(\"the learning algorithm must be a character string.\")\n\n  # select the right class of algorithms.\n  if (\"constraint\" %in% class)\n    ok = c(ok, constraint.based.algorithms)\n  if (\"markov.blanket\" %in% class)\n    ok = c(ok, markov.blanket.algorithms)\n  if (\"neighbours\" %in% class)\n    ok = c(ok, local.search.algorithms)\n  if (\"score\" %in% class)\n    ok = c(ok, score.based.algorithms)\n  if (\"mim\" %in% class)\n    ok = c(ok, mim.based.algorithms)\n  if (\"classifier\" %in% class)\n    ok = c(ok, classifiers)\n  if (\"all\" %in% class)\n    ok = available.learning.algorithms\n\n  if (algorithm %!in% ok)\n       stop(\"valid learning algorithms are:\\n\",\n            sprintf(\"    %-15s %s\\n\", ok, method.labels[ok]))\n\n  return(algorithm)\n\n}#CHECK.LEARNING.ALGORITHM\n\n# check the aruments of a learning algorithm (for use in bootstrap).\ncheck.learning.algorithm.args = function(args, algorithm, bn) {\n\n  # convert args into a list, if it's not one already.\n  if (!is.list(args))\n      args = as.list(args)\n\n  # if a reference bn is specified, guess as many parameters as possbile.\n  if (!(missing(algorithm) || missing(bn))) {\n\n    # use the same score/conditional independence test.\n    if (algorithm %in% constraint.based.algorithms) {\n\n      # it's essential to check it's actually an independence test,\n      # it could be a score function or NA.\n      if (\"test\" %!in% names(args))\n        if (bn$learning$test %in% available.tests)\n          args$test = bn$learning$test\n\n      # set the appropriate value for the optimization flag.\n      if (\"optimized\" %!in% names(args))\n        args$optimized = bn$learning$optimized\n\n      # pass along all the parameters in bn$learning$args.\n      if (length(bn$learning$args) > 0) {\n\n        if (\"alpha\" %!in% names(args))\n          args$alpha = bn$learning$args$alpha\n\n        if (\"test\" %in% names(args) && (\"B\" %!in% names(args)))\n          if (args$test %in% resampling.tests)\n            args$B = bn$learning$args$B\n\n      }#THEN\n\n    }#THEN\n    else if (algorithm %in% score.based.algorithms) {\n\n      if (\"score\" %!in% names(args))\n        if (bn$learning$test %in% available.scores)\n          args$score = bn$learning$test\n\n      # set the appropriate value for the optimization flag.\n      if (\"optimized\" %!in% names(args))\n        args$optimized = bn$learning$optimized\n\n      # pass along the relevant parameters in bn$learning$args if the score\n      # function is the same (hint: different scores have paramenters with\n      # the same name but different meanings).\n      if ((\"score\" %in% names(args)) && (args$score == bn$learning$test))\n        for (arg in names(bn$learning$args))\n          if ((arg %!in% names(args)) && (arg %in% (score.extra.args[[args$score]])))\n            args[[arg]] = bn$learning$args[[arg]]\n\n    }#THEN\n\n    # pass along whitelist and blacklist.\n    if (!is.null(bn$learning$whitelist))\n      args$whitelist = bn$learning$whitelist\n    if (!is.null(bn$learning$blacklist))\n      args$blacklist = bn$learning$blacklist\n\n  }#THEN\n\n  # remove any spurious x arguments, the data are provided by the bootstrap.\n  if (\"x\" %in% names(args)) {\n\n    args$x = NULL\n\n    warning(\"removing 'x' from 'algorithm.args', the data set is provided by the bootstrap sampling.\")\n\n  }#THEN\n\n  return(args)\n\n}#CHECK.LEARNING.ALGORITHM.ARGS\n\n# check the number of bootstrap replicates.\ncheck.replicates = function(R, default = 200) {\n\n  if (missing(R) || is.null(R))\n    R = default\n  else if (!is.positive.integer(R))\n    stop(\"the number of bootstrap replicates must be a positive integer.\")\n\n  return(R)\n\n}#CHECK.RESAMPLING\n\n# check the size of bootstrap replicates.\ncheck.bootsize = function(m, data, default = nrow(data)) {\n\n  if (missing(m) || is.null(m))\n    m = default\n  else if (!is.positive.integer(m))\n    stop(\"bootstrap sample size must be a positive integer.\")\n\n  return(m)\n\n}#CHECK.BOOTSIZE\n\n# check a prior distribution against the observed variable.\ncheck.classifier.prior = function(prior, training) {\n\n  if (missing(prior) || is.null(prior)) {\n\n    # use the empirical probabilities in the fitted network, or a flat prior\n    # as a last resort.\n    if (is(training, c(\"bn.fit.dnode\", \"bn.fit.onode\")))\n      prior = training$prob\n    else\n      prior = rep(1, nlevels(training))\n\n  }#THEN\n  else {\n\n    if (is(training, c(\"bn.fit.dnode\", \"bn.fit.onode\")))\n      nlvls = dim(training$prob)[1]\n    else\n      nlvls = nlevels(training)\n\n    if (length(prior) != nlvls)\n      stop(\"the prior distribution and the training variable have a different number of levels.\")\n    if (!is.nonnegative.vector(prior))\n      stop(\"the prior distribution must be expressed as a probability vector.\")\n\n    # make sure the prior probabilities sum to one.\n    prior = prior / sum(prior)\n\n  }#ELSE\n\n  return(prior)\n\n}#CHECK.CLASSIFIER.PRIOR\n\n# check a vector of weights.\ncheck.weights = function(weights, len) {\n\n  if (missing(weights) || is.null(weights)) {\n\n    weights = rep(1, len)\n\n  }#THEN\n  else {\n\n    if (!is.nonnegative.vector(weights))\n      stop(\"missing or negative weights are not allowed.\")\n\n    if (length(weights) != len)\n      stop(\"wrong number of weights, \", length(weights),\n        \" weights while \", len, \" are needed.\")\n\n    weights = prop.table(weights)\n\n  }#ELSE\n\n  return(weights)\n\n}#CHECK.WEIGHTS\n\n# check a user-specified bn.fit.gnode.\ncheck.fit.gnode.spec = function(x, node) {\n\n  components =  c(\"coef\", \"fitted\", \"resid\", \"sd\", \"configs\")\n  labels = c(fitted = \"fitted values\", resid = \"residuals\")\n\n  # custom list of components.\n  if (!is.list(x) || any(names(x) %!in% components))\n    stop(\"the conditional probability distribution for node \", node,\n         \" must be a list with at least one of the following elements:\",\n         paste0(\" '\", components, \"'\"), \".\")\n  if ((\"coef\" %!in% names(x)) || !any(c(\"sd\", \"resid\") %in% names(x)))\n    stop(\"at least the regression coefficients and either the residuals or \",\n      \"the residual standard deviation are required for node \", node, \".\")\n  # discrete parents' configurations only belong to bn.fit.cgnode.\n  if ((length(dim(x$coef)) != 2) && (\"configs\" %in% names(x)))\n    stop(\"no parents' configurations are needed with a single set of coefficients.\")\n\n  if (!is.null(x$coef))\n    if ((length(x$coef) == 0) || !is.real.vector(x$coef))\n      stop(\"coef must be a vector or a matrix of numeric values, the \",\n        \"regression coefficients for node \", node, \" given its parents.\")\n\n  for (comp in c(\"fitted\", \"resid\"))\n    if (!is.null(x[[comp]]))\n      if ((length(x[[comp]]) == 0) || !is.real.vector(x[[comp]]))\n        stop(comp, \" must be a vector of numeric values, the \",\n          labels[comp], \" for node \", node, \" given its parents.\")\n\n  if (!is.null(x$configs))\n    if ((length(x$configs) == 0) || !is.factor(x$configs))\n      stop(\"the discrete parents' configurations for node \", node,\n        \" must be a factor.\")\n\n  # check the standard deviation of the residuals.\n  if (!is.null(x$sd)) {\n\n    if (!is.nonnegative.vector(x$sd))\n      stop(\"sd must be a non-negative number, the standard deviation of the \",\n        \"residuals of node \", node, \".\")\n\n    if ((length(dim(x$coef)) == 2) && (length(x$sd) != ncol(x$coef)) ||\n        (length(dim(x$coef)) == 1) && (length(x$sd) > 1) ||\n        (length(dim(x$sd)) > 1))\n      stop(\"the dimensions of sd and coef do not match.\")\n\n    if (!is.null(x$resid) && (length(x$sd) == 1)) {\n\n      adj.sd = cgsd(x$resid, p = length(x$coef))\n\n      if (!isTRUE(all.equal(x$sd, adj.sd, check.attributes = FALSE, tol = 0.0005)))\n        stop(\"the reported standard deviation of the residuals of node \", node,\n          \" does not match the observed one.\")\n\n    }#THEN\n    else if (!is.null(x$resid) && (length(x$sd) > 1) && !is.null(x$configs)) {\n\n      adj.sd = cgsd(x$resid, configs = x$configs, p = nrow(x$coef))\n\n      if (!isTRUE(all.equal(x$sd, adj.sd, check.attributes = FALSE, tol = 0.0005)))\n        stop(\"the reported standard deviation of the residuals of node \", node,\n          \" does not match the observed one.\")\n\n    }#THEN\n\n  }#THEN\n  else if (!is.null(x$resid)) {\n\n    # compute the standard error from the residuals if possible.\n    if ((length(dim(x$coef)) == 2) && is.null(x$config))\n      stop(\"sd is missing, and parents' configurations are required to compute it.\")\n\n    x$sd = cgsd(x$resid, configs = x$configs,\n             p = ifelse(is.matrix(x$coef), nrow(x$coef), length(x$coef)))\n\n  }#THEN\n\n  # one residual for each fitted value.\n  if (!is.null(x$resid) && !is.null(x$fitted))\n    if (length(x$resid) != length(x$fitted))\n      stop(\"the residuals and the fitted values of node \", node,\n        \" have different lengths.\")\n  # if any, one parent configuration for each fitted value and residual.\n  if (!is.null(x$config)) {\n\n    if (!is.null(x$resid) && (length(x$configs) != length(x$resid)))\n      stop(\"parents' configurations and residuals of node \", node,\n        \" have different lengths.\")\n    if (!is.null(x$fitted) && (length(x$configs) != length(x$fitted)))\n      stop(\"parents' configurations and fitted values of node \", node,\n        \" have different lengths.\")\n\n  }#THEN\n\n  return(x)\n\n}#CHECK.FIT.GNODE.SPEC\n\n# check one bn.fit.gnode against another.\ncheck.gnode.vs.spec = function(new, old, node) {\n\n  if (is(old, \"bn.fit.gnode\")) {\n\n    # same number of coefficients.\n    if (length(new$coef) != length(old$coefficients))\n      stop(\"wrong number of coefficients for node \", old$node, \".\")\n    # if the new coefficients have labels, they must match.\n    if (!is.null(names(new$coef)))\n      check.nodes(names(new$coef), graph = names(old$coefficients),\n        min.nodes = length(names(old$coefficients)))\n    else\n      names(new$coef) = names(old$coef)\n    # same number of residuals.\n    if (!is.null(new$resid))\n      if (length(new$resid) != length(old$residuals))\n        stop(\"wrong number of residuals for node \", old$node, \".\")\n    # same number of fitted values.\n    if (!is.null(new$fitted))\n      if (length(new$fitted) != length(old$fitted.values))\n        stop(\"wrong number of fitted values for node \", old$node, \".\")\n\n  }#THEN\n  else {\n\n    # add the intercept, which is obviously not among the parents of the node.\n    old = c(\"(Intercept)\", old)\n\n    # same number of coefficients.\n    if (length(new$coef) != length(old))\n      stop(\"wrong number of coefficients for node \", node, \".\")\n    # if the new coefficients have labels, they must match.\n    if (!is.null(names(new$coef)))\n      check.nodes(names(new$coef), graph = old, min.nodes = length(old))\n    else\n      names(new$coef) = old\n\n  }#ELSE\n\n  return(new)\n\n}#CHECK.GNODE.VS.SPEC\n\n# check one bn.fit.gnode against another.\ncheck.cgnode.vs.spec = function(new, old, node) {\n\n  if (is(old, \"bn.fit.cgnode\")) {\n\n    # right dimensions for the coefficients.\n    if (!is(new$coef, \"matrix\") ||\n        !identical(dim(new$coef), dim(old$coefficients)))\n      stop(\"the regression coefficients for node \", old$node, \" must be \",\n           \"in a matrix with one column for each discrete parent and one \",\n           \"coefficient for each continuous parent.\")\n    # if the new coefficients have labels, they must match.\n    if (!is.null(rownames(new$coef)))\n      check.nodes(rownames(new$coef), graph = rownames(old$coefficients),\n        min.nodes = length(rownames(old$coefficients)))\n    # same number of residuals.\n    if (!is.null(new$resid))\n      if (length(new$resid) != length(old$residuals))\n        stop(\"wrong number of residuals for node \", old$node, \".\")\n    # same number of fitted values.\n    if (!is.null(new$fitted))\n      if (length(new$fitted) != length(old$fitted.values))\n        stop(\"wrong number of fitted values for node \", old$node, \".\")\n\n  }#THEN\n  else {\n\n    # nothing useful can possibly be checked from the parent labels.\n\n  }#ELSE\n\n}#CHECK.CGNODE.SPEC\n\n# check a user-specified bn.fit.dnode.\ncheck.fit.dnode.spec = function(x, node) {\n\n  # the CPT must be a table.\n  if (!is.ndmatrix(x))\n    stop(\"the conditional probability distribution of node \", node,\n      \" must be a table, a matrix or a multidimensional array.\")\n  # all elements must be probabilities.\n  if (!is.probability.vector(x))\n    stop(\"some elements of the conditional probability distributions of node \",\n      node, \" are not probabilities.\")\n\n  # convert the CPT into a table object.\n  x = as.table(x)\n\n  # compute the dimensions of the table\n  dims = dim(x)\n  ndims = length(dims)\n  # flatten 1xc tables into 1-dimensional ones.\n  if ((ndims == 2) && (dims[1] == 1))\n    x = flatten.2d.table(x)\n  # update dims and ndims.\n  dims = dim(x)\n  ndims = length(dims)\n\n  # normalization.\n  if (ndims == 1) {\n\n    if (abs(sum(x) - 1) > 0.01)\n      stop(\"the probability distribution of node \", node, \" does not sum to one.\")\n\n    x = x / sum(x)\n\n  }#THEN\n  else {\n\n    check.sum = sapply(margin.table(x,  seq(from = 2, to = ndims)),\n                  function(x) abs(sum(x) - 1) > 0.01)\n\n    if (any(check.sum))\n      stop(\"some conditional probability distributions of node \", node, \" do not sum to one.\")\n\n    x = prop.table(x, margin = seq(ndims)[-1])\n\n  }#ELSE\n\n  return(x)\n\n}#CHECK.FIT.DNODE.SPEC\n\n# check one bn.fit.dnode against another.\ncheck.dnode.vs.spec = function(new, old, node, cpt.levels) {\n\n  ndims = length(dim(new))\n\n  if (is(old, c(\"bn.fit.dnode\", \"bn.fit.onode\"))) {\n\n    # same dimensions.\n    if (!identical(dim(new), dim(old$prob)))\n      stop(\"wrong dimensions for node \", old$node, \".\")\n    # if the new CPT has labels, they must match (and be in the same order too).\n    if (!is.null(dimnames(new)))\n      if (!identical(dimnames(new), dimnames(old$prob)))\n        stop(\"wrong levels for node \", old$node, \".\")\n\n  }#THEN\n  else {\n\n    # same dimensions and labels.\n    if (ndims == 1) {\n\n      if (dim(new) != length(cpt.levels[[node]]))\n        stop(\"wrong dimensions for node \", node, \".\")\n      if (!identical(cpt.levels[[node]], names(new)))\n        stop(\"wrong levels for node \", node, \".\")\n\n    }#THEN\n    else {\n\n      # check whether all the CPT inclues all the relevant variables.\n      if(!setequal(names(dimnames(new)), c(node, old)))\n        stop(\"wrong dimensions for node \", node, \".\")\n      # now that we are sure that the dimensions are the right ones, reorder\n      # them to follow the ordering of the parents in the network.\n      d = names(dimnames(new))\n      new = aperm(new, c(match(node, d), match(old, d)))\n      # check whether the margins of the CPT are right.\n      if (any(dim(new) != sapply(cpt.levels[c(node, old)], length)))\n        stop(\"wrong number of dimensions for node \", node, \".\")\n      if (!identical(cpt.levels[c(node, old)], dimnames(new)))\n        stop(\"wrong levels for node \", node, \".\")\n\n    }#ELSE\n\n  }#ELSE\n\n  return(new)\n\n}#CHECK.DNODE.VS.SPEC\n\n# check evidence in list format for mutilated networks.\ncheck.mutilated.evidence = function(evidence, graph) {\n\n  # check whether evidence is there.\n  if (missing(evidence))\n    stop(\"evidence must be a list with elements named after the nodes in the graph.\")\n  # if evindence is TRUE there's nothing to check.\n  if (identical(evidence, TRUE))\n    return(TRUE)\n  # check whether evidence is a named list.\n  if(!is(evidence, \"list\"))\n    stop(\"evidence must be a list with elements named after the nodes in the graph.\")\n  # check the node labels in evidence.\n  check.nodes(names(evidence), graph = graph)\n\n  if (is(graph, \"bn\")) {\n\n    # check the network is completely directed.\n    if (!is.dag(graph$arcs, names(graph$nodes)))\n      stop(\"the graph is only partially directed.\")\n\n  }#THEN\n  else {\n\n     # check the evidence is appropriate for the nodes.\n     for (fixed in names(evidence)) {\n\n       # extract the node and the evidence.\n       cur = graph[[fixed]]\n       ev = evidence[[fixed]]\n\n       if (is(cur, c(\"bn.fit.dnode\", \"bn.fit.onode\"))) {\n\n         if (is.factor(ev))\n           evidence[[fixed]] = ev = as.character(ev)\n\n         if (!is.string.vector(ev) || any(ev %!in% dimnames(cur$prob)[[1]]))\n           stop(\"the evidence for node \", fixed, \" must be valid levels.\")\n\n       }#THEN\n       else if (is(cur, \"bn.fit.gnode\")) {\n\n         # for continuous nodes evidence must be real numbers.\n         if (!is.real.vector(ev) || (length(ev) %!in% 1:2))\n           stop(\"the evidence \", fixed, \" must be a real number or a finite interval.\")\n         storage.mode(ev) = \"double\"\n         # amke sure interval boundaries are in the right order.\n         evidence[[fixed]] = sort(ev)\n\n       }#THEN\n\n     }#FOR\n\n  }#THEN\n\n  return(evidence)\n\n}#CHECK.MUTILATED.EVIDENCE\n\n",
    "created" : 1458746451153.000,
    "dirty" : false,
    "encoding" : "UTF-8",
    "folds" : "",
    "hash" : "2672424150",
    "id" : "89E64B7E",
    "lastKnownWriteTime" : 1457435976,
    "last_content_update" : 1457435976,
    "path" : "~/sources/bnlearn/R/utils-sanitization.R",
    "project_path" : "R/utils-sanitization.R",
    "properties" : {
    },
    "relative_order" : 5,
    "source_on_save" : false,
    "source_window" : "",
    "type" : "r_source"
}